<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="A novel algorithm to convert optimized 2D Gaussians from Gaussian splatting to holograms.">
  <meta name="keywords" content="holography, holographic displays, gaussian splatting, neural rendering, 3DGS, wave propagation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title></title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-full-width">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">
            <!-- <span style="font-weight: 900;">UniFusion</span><br><span style="font-weight: 100;">Vision-Language Model as Unified Encoder for Image Generation</span> -->
            <span style="font-weight: 900;">UniFusion</span>
          </h1>
          <h2 class="title is-2 publication-title">
            <span style="font-weight: 100;">Vision-Language Model as Unified Encoder for Image Generation</span>
          </h2>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://thekevinli.github.io">Kevin (Yu-Teng) Li</a>*
            </span>
            <span class="author-block">
              <a href="">Manuel Brack</a>*
            </span>
            <span class="author-block">
              <a href="">Sudeep Katakol</a>
            </span>
            <span class="author-block">
              <a href="">Hareesh Ravi</a>
            </span>
            <span class="author-block">
              <a href="">Ajinkya Kale</a>
            </span>
            <!-- <p style="font-size: smaller;">*Equal contributions</p> -->
            <p style="font-size: .9rem; margin-top: 4px; margin-bottom: 4px;">* Equal contributions. Kevin led the model design and ablations. Manuel led the evaluation and paper writing.</p>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Adobe</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!--
              <span class="link-block">
                <a href="static/files/textured_gaussians_main.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
            -->
              <!-- Arxiv Link. -->
              
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=ttDCDbhEf7Q"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              
              <!-- <span class="link-block">
                <a href="https://drive.google.com/drive/folders/15FvHyIU-k80BaLLSV0zGOM_WidRPoo4U"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-google-drive"></i>
                  </span>
                  <span>Paper (High-Res & Compressed)</span>
                </a>
              </span> -->
              
              <!--
              <span class="link-block">
                <a href=""
                   class="button is-normal is-rounded is-dark">
                  <span>Results</span>
                  </a>
              </span>
              -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Coming Soon)</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="teaser-video-container">
        <div class="teaser-video-wrapper" id="teaser-video-wrapper">
          <img id="teaser-thumbnail" src="./static/images/unifusion_arch.png" alt="UniFusion Architecture" />
        </div>
      </div>
      <!-- <p class="has-text-centered is-7" style="margin-top: 5px; margin-bottom: 5px;"><strong>UniFusion Architecture</strong></p> -->
      <h2 class="subtitle has-text-centered">
        <strong>UniFusion</strong> is the first architecture that uses only VLM as input-condition encoder without auxiliary signals from VAE or CLIP to do editing. The unified encoder framework and our proposed Layerwise Attention Pooling (LAP) module enables emergent capabilities such as <strong>zero-shot multi-ref generation</strong> when trained on single-reference pairs, and capability transfer where training on Editing helps T2I quantitatively and qualitatively.
      </h2>
    </div>
  </div>
</section>



<section class="section">
  <!-- Text-to-Image Results -->
  <div class="container">
    <h2 class="title is-3 has-text-centered">Text-to-Image Results</h2>
    <div class="collage" id="image-collage">
      <a class="collage-item portrait" href="./static/images/text_to_image/portrait_unifusion_zeroshot_768x1080.png">
        <img src="./static/images/text_to_image/portrait_unifusion_zeroshot_768x1080.png" alt="portrait_unifusion_zero_shot" loading="lazy">
      </a>
      <a class="collage-item landscape" href="./static/images/text_to_image/landscape_0.png">
        <img src="./static/images/text_to_image/landscape_0.png" alt="landscape_0" loading="lazy">
      </a>
      <a class="collage-item landscape" href="./static/images/text_to_image/landscape_0009_0000-2.png">
        <img src="./static/images/text_to_image/landscape_0009_0000-2.png" alt="landscape_0009_0000-2" loading="lazy">
      </a>
      <a class="collage-item landscape" href="./static/images/text_to_image/landscape_8.png">
        <img src="./static/images/text_to_image/landscape_8.png" alt="landscape_8" loading="lazy">
      </a>
      <!-- <a class="collage-item portrait" href="./static/images/text_to_image/portrait_18.png">
        <img src="./static/images/text_to_image/portrait_18.png" alt="portrait_18" loading="lazy">
      </a> -->
      <a class="collage-item landscape" href="./static/images/text_to_image/landscape_11.png">
        <img src="./static/images/text_to_image/landscape_11.png" alt="landscape_11" loading="lazy">
      </a>
      <a class="collage-item landscape" href="./static/images/text_to_image/landscape_13.png">
        <img src="./static/images/text_to_image/landscape_13.png" alt="landscape_13" loading="lazy">
      </a>
      <a class="collage-item landscape" href="./static/images/text_to_image/landscape_14.png">
        <img src="./static/images/text_to_image/landscape_14.png" alt="landscape_14" loading="lazy">
      </a>
      <a class="collage-item portrait" href="./static/images/text_to_image/portrait_3_512x720.png">
        <img src="./static/images/text_to_image/portrait_3_512x720.png" alt="portrait_3" loading="lazy">
      </a>
      <!-- <a class="collage-item portrait" href="./static/images/text_to_image/portrait_7.png">
        <img src="./static/images/text_to_image/portrait_7.png" alt="portrait_7" loading="lazy">
      </a> -->
      <a class="collage-item landscape" href="./static/images/text_to_image/landscape_18.png">
        <img src="./static/images/text_to_image/landscape_18.png" alt="landscape_18" loading="lazy">
      </a>
      <a class="collage-item landscape" href="./static/images/text_to_image/landscape_20.png">
        <img src="./static/images/text_to_image/landscape_20.png" alt="landscape_20" loading="lazy">
      </a>
    </div>
  </div>
</section>


<section class="section">
  <!-- Text-to-Image Results -->
  <div class="container">
    <h2 class="title is-3 has-text-centered">Single-reference editing results</h2>
    <h2 class="subtitle has-text-centered">
      Hover to see the full edited image and instruction prompts.
    </h2>
    <div class="collage collage--editing" id="image-collage-editing">
    <!-- <div class="collage" id="image-collage"> -->
      <a class="collage-item portrait" href="./static/images/single_ref_editing/portrait_005_character_repose.png">
        <img src="./static/images/single_ref_editing/portrait_005_character_repose.png" alt="portrait_005_character_repose" loading="lazy">
      </a>
      <a class="collage-item portrait" href="./static/images/single_ref_editing/portrait_001_color_change.png">
        <img src="./static/images/single_ref_editing/portrait_001_color_change.png" alt="portrait_001_color_change" loading="lazy">
      </a>
      <a class="collage-item landscape" href="./static/images/single_ref_editing/landscape_001_text_editing.png">
        <img src="./static/images/single_ref_editing/landscape_001_text_editing.png" alt="landscape_001_text_editing" loading="lazy">
      </a>
      <a class="collage-item landscape" href="./static/images/single_ref_editing/landscape_002_character_repose.png">
        <img src="./static/images/single_ref_editing/landscape_002_character_repose.png" alt="landscape_002_character_repose" loading="lazy">
      </a>
      <a class="collage-item square" href="./static/images/single_ref_editing/square_001_expression_change.png">
        <img src="./static/images/single_ref_editing/square_001_expression_change.png" alt="square_001_expression_change" loading="lazy">
      </a>
      <a class="collage-item portrait" href="./static/images/single_ref_editing/portrait_002_character_repose.png">
        <img src="./static/images/single_ref_editing/portrait_002_character_repose.png" alt="portrait_002_character_repose" loading="lazy">
      </a>
      <a class="collage-item landscape" href="./static/images/single_ref_editing/landscape_003_text_editing.png">
        <img src="./static/images/single_ref_editing/landscape_003_text_editing.png" alt="landscape_003_text_editing" loading="lazy">
      </a>
      <a class="collage-item portrait" href="./static/images/single_ref_editing/portrait_003_object_extraction.png">
        <img src="./static/images/single_ref_editing/portrait_003_object_extraction.png" alt="portrait_003_object_extraction" loading="lazy">
      </a>
      <a class="collage-item landscape" href="./static/images/single_ref_editing/landscape_004_stylization.png">
        <img src="./static/images/single_ref_editing/landscape_004_stylization.png" alt="landscape_004_stylization" loading="lazy">
      </a>
      <a class="collage-item portrait" href="./static/images/single_ref_editing/portrait_004_character_repose.png">
        <img src="./static/images/single_ref_editing/portrait_004_character_repose.png" alt="portrait_004_character_repose" loading="lazy">
      </a>
      <a class="collage-item landscape" href="./static/images/single_ref_editing/portrait_006_extraction_change_ar.png">
        <img src="./static/images/single_ref_editing/portrait_006_extraction_change_ar.png" alt="portrait_006_extraction_change_ar" loading="lazy">
      </a>
    </div>
  </div>
</section>

 
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="carousel-label" class="column is-full-width">
        <div class="column has-text-centered">
          <h2 class="title is-4">Zero-shot multi-reference generations</h2>
        </div>
      </div>
      <div id="carousel-div" class="carousel results-carousel">
        <div class="item item-room">
          <video poster="" id="room" autoplay muted loop playsinline height="100%">
            <source src="static/videos/room_full_1M_focal_stack_insets.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-stump">
          <video poster="" id="stump" autoplay muted loop playsinline height="100%">
            <source src="static/videos/stump_full_1M_focal_stack_insets.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-garden">
          <video poster="" id="garden" autoplay muted loop playsinline height="100%">
            <source src="static/videos/garden_full_1M_focal_stack_insets.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-kitchen">
          <video poster="" id="kitchen" autoplay muted loop playsinline height="100%">
            <source src="static/videos/kitchen_full_1M_focal_stack_insets.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-hotdog">
          <video poster="" id="hotdog" autoplay muted loop playsinline height="100%">
            <source src="static/videos/hotdog_full_1M_focal_stack_insets.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-lego">
          <video poster="" id="lego" autoplay muted loop playsinline height="100%">
            <source src="static/videos/lego_full_1M_focal_stack_insets.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-ship">
          <video poster="" id="ship" autoplay muted loop playsinline height="100%">
            <source src="static/videos/ship_full_1M_focal_stack_insets.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-materials">
          <video poster="" id="materials" autoplay muted loop playsinline height="100%">
            <source src="static/videos/materials_full_1M_focal_stack_insets.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair">
          <video poster="" id="chair" autoplay muted loop playsinline height="100%">
            <source src="static/videos/chair_full_1M_focal_stack_insets.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <br>
      <p class="has-text-centered">
        We experimentally captured 3D focal stacks of generated holograms on a holographic display prototype.
      </p>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We present UniFusion, a diffusion-based generative model conditioned on a frozen large vision-language model (VLM) that serves as a unified multimodal encoder. Although recent advances in visual generation have been remarkable, most existing architectures still depend on distinct encoders for images (e.g., Variational Autoencoder i.e. VAE features) and text (e.g., T5 or CLIP). This separation constrains diffusion models’ ability to perform cross-modal reasoning and knowledge transfer. Prior attempts to bridge this gap often perform shallow fusion of information from VLM without enough generalization, employ multiple visual encoders, or train large unified VLMs jointly for text and image generation—approaches that demand substantial computational resources and large-scale data, limiting accessibility. To reap the benefits of the joint multimodal reasoning and representation capacity of VLMs, we propose UniFusion. 
          </p>

          <!-- <p>
            Specifically, we derive a closed-form solution for a 2D Gaussian-to-hologram transform that supports 
            occlusions and alpha blending. Inspired by classic computer graphics techniques, we also derive an efficient 
            approximation of the aforementioned process in the Fourier domain that is easily parallelizable and 
            implement it using custom CUDA kernels. 
          </p> -->
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section fullwidth-gray-bg">
  <div class="container is-max-desktop">
<!-- Model Pipeline. -->
<div class="columns is-centered has-text-centered">
  <div class="column is-full-width">
    <h2 class="title is-3">Method Overview</h2>
    <div class="content has-text-centered">
      <img src="./static/images/overview.svg" style="width: 100%;">
    </div>
    <div class="content has-text-justified">
      <p>
        <strong>Gaussian Wave Splatting (GWS)</strong> takes a set of optimized <a href="https://surfsplatting.github.io/">2D Gaussians </a> 
        as input and outputs a hologram that can be directly displayed on emerging holographic displays. In the high level,
        each 2D Gaussian primitive is illuminated by a coherent illumination source, and the resulting illuminated and propagated wavefront 
        is recorded on a spatial light modulator (SLM) to generate the hologram. Since the parameters of the Gaussians already explicitly encode 3D informtation, 
        further splatting Gaussians using a physically-accurate wave propagation model allows for the direct reconstruction of 
        3D focal stacks with natural defocus blur when viewed on a holographic display.
      </p>
    </div>
    <div class="content has-text-centered">
      <img src="./static/images/ray_wave_comparison.svg" style="width: 100%;">
    </div>
    <div class="content has-text-justified">
      <p>
        Aside from deriving the exact mathematical formulation of the Fourier spectrum of arbitrarily oriented 2D Gaussians for splatting, 
        we also derived the wave optics-counterpart of alpha blending (right) for Gaussian primitives, which is the major building block in 
        the original geometric optics-based Gaussian splatting pipeline (left) to accurately model occlusion.
      </p>
    </div>
    <div class="content has-text-centered">
      <div class="video-grid" id="syncedVideoGrid">
        <div class="video-cell">
          <video class="synced-video" autoplay muted loop playsinline>
            <source src="./static/videos/kitchen_pc_match_focal_stack_insets.mp4" type="video/mp4">
          </video>
          <p class="video-label">Point cloud</p>
        </div>
        <div class="video-cell">
          <video class="synced-video" autoplay muted loop playsinline>
            <source src="./static/videos/kitchen_mesh_match_focal_stack_insets.mp4" type="video/mp4">
          </video>
          <p class="video-label">Polygon-based CGH</p>
        </div>
        <div class="video-cell">
          <video class="synced-video" autoplay muted loop playsinline>
            <source src="./static/videos/kitchen_full_matched_focal_stack_insets.mp4" type="video/mp4">
          </video>
          <p class="video-label">Ours GWS (full)</p>
        </div>
        <div class="video-cell">
          <video class="synced-video" autoplay muted loop playsinline>
            <source src="./static/videos/kitchen_fast_1M_focal_stack_insets.mp4" type="video/mp4">
          </video>
          <p class="video-label">Ours GWS (fast)</p>
        </div>
      </div>
    </div>
    <div class="content has-text-justified">
      <p class="has-text-centered" style="font-size: smaller;">(hover over the videos to pause)</p>
      <p>
        GWS achieves superior 3D focal stack reconstruction quality compared to prior primitives-based computer generated holography 
        algorithms based on point clouds and per-face textured meshes (polygon-based CGH). We also designed a fast variant of GWS based on an approximated 
        volume rendering image formation model inspired by order-invariant transparency (OIT) in traditional computer graphics.
        We implemented custom CUDA kernels for this fast GWS variant, achieving a 30X speedup compared the full, exact GWS with only a small drop in image quality.
      </p>
    </div>
  </div>
</div>
<!--/ Model Pipeline -->
</div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Interactive Comparisons</h2>
        
        <div class="columns is-variable is-4">
          <!-- Left side controls -->
          <div class="column is-5">
            <div class="box">
              <h3 class="subtitle is-4 has-text-centered">CGH Algorithm Comparisons</h3>
              
              <!-- Scene selector -->
              <div class="field">
                <label class="label">Scene</label>
                <div class="control">
                  <div class="select is-fullwidth">
                    <select id="scene-selector">
                      <option value="room">Room</option>
                      <option value="stump">Stump</option>
                      <option value="garden">Garden</option>
                      <option value="kitchen">Kitchen</option>
                      <option value="materials">Materials</option>
                      <option value="lego">Lego</option>
                      <option value="chair">Chair</option>
                      <option value="ship">Ship</option>
                    </select>
                  </div>
                </div>
              </div>
              
              <!-- Model selector buttons -->
              <div class="field">
                <label class="label">CGH Method</label>
                <div class="buttons has-addons is-centered model-buttons">
                  <button class="button is-active" data-model="pc_match">Point Cloud</button>
                  <button class="button" data-model="mesh_match">Polygon-based CGH</button>
                  <button class="button" data-model="full_matched">Full GWS</button>
                  <button class="button" data-model="fast_1M">Fast GWS</button>
                </div>
              </div>
              
              <div class="content has-text-justified mt-4">
                <p class="description-text">
                  Select different scenes and CGH methods to compare the
                  3D focal stack reconstruction quality of holograms.
                  The GWS models show superior image stack quality compared to traditional 
                  point cloud and mesh-based approaches.
                </p>
              </div>
            </div>
          </div>
          
          <!-- Right side video display -->
          <div class="column is-7">
            <div class="box video-container has-text-centered">
              <video id="comparison-video" autoplay muted loop playsinline style="width: 100%; border: 2px solid black;">
                <source src="./static/videos/room_pc_match_focal_stack_insets.mp4" type="video/mp4">
              </video>
              <p class="video-caption mt-2">Focal stack reconstruction</p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<footer class="footer" class="fullwidth-gray-bg">
  <div class="container">
    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>
          @article{choi2025gaussian,
            title={Gaussian Wave Splatting for Computer-generated Holography},
            author={Choi, Suyeon and Chao, Brian and Yang, Jacqueline and Gopakumar, Manu and Wetzstein, Gordon},
            journal={ACM Transactions on Graphics (TOG)},
            volume={44},
            number={4},
            pages={1–13},
            year={2025},
            publisher={ACM New York, NY, USA}
            }
        </code></pre>
      </div>
    </section>
    <div class="content has-text-centered">
      
      <a class="icon-link"
         href="https://arxiv.org/pdf/2505.06582">
        <i class="ai ai-arxiv"></i>
      </a>
    
      <a class="icon-link" href="" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
      <a class="icon-link" href="https://drive.google.com/file/d/1tdLECuTQ-z7GU1ueCJBeKqGuSVu9Lbry/view?usp=sharing" class="external-link" disabled>
        <i class="fab fa-google-drive"></i>
      </a>
      <br>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
