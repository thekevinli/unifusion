<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="UniFusion proposes a framework which uses VLMs as unified encoders for image generation and editing.">
  <meta name="keywords" content="vision-language model, VLM, diffusion transformer, flow matching, image generation, image editing, unified models, unifusion">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>UniFusion</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" type="image/png" href="./static/images/adobe_icon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-full-width">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">
            <!-- <span style="font-weight: 900;">UniFusion</span><br><span style="font-weight: 100;">Vision-Language Model as Unified Encoder for Image Generation</span> -->
            <span style="font-weight: 900;">UniFusion</span>
          </h1>
          <h2 class="title is-2 publication-title">
            <span style="font-weight: 100;">Vision-Language Model as Unified Encoder for Image Generation</span>
          </h2>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://thekevinli.github.io">Kevin (Yu-Teng) Li</a>*
            </span>
            <span class="author-block">
              <a href="">Manuel Brack</a>*
            </span>
            <span class="author-block">
              <a href="">Sudeep Katakol</a>
            </span>
            <span class="author-block">
              <a href="">Hareesh Ravi</a>
            </span>
            <span class="author-block">
              <a href="">Ajinkya Kale</a>
            </span>
            <!-- <p style="font-size: smaller;">*Equal contributions</p> -->
            <p style="font-size: .9rem; margin-top: 4px; margin-bottom: 4px;">* Equal contributions. Kevin led the model design and ablations. Manuel led the evaluation and paper writing.</p>
          </div>

          <div class="is-size-5 publication-authors">
            <!-- <span class="author-block">Adobe</span> -->
            <span class="author-block">
              <img src="./static/images/adobe_wordmark_rgb_red.png" width="100px" style="margin: 10px"/>
            </span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!--
              <span class="link-block">
                <a href="static/files/textured_gaussians_main.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
            -->
              <!-- Arxiv Link. -->
              
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>ArXiv</span>
                </a>
              </span>
              
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=ttDCDbhEf7Q"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-google-drive"></i>
                  </span>
                  <span>High-res paper</span>
                </a>
              </span>
              
              <!--
              <span class="link-block">
                <a href=""
                   class="button is-normal is-rounded is-dark">
                  <span>Results</span>
                  </a>
              </span>
              -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Coming Soon)</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="teaser-video-container">
        <div class="teaser-video-wrapper" id="teaser-video-wrapper">
          <img id="teaser-thumbnail" src="./static/images/unifusion_arch.png" alt="UniFusion Architecture" />
        </div>
      </div>
      <!-- <p class="has-text-centered is-7" style="margin-top: 5px; margin-bottom: 5px;"><strong>UniFusion Architecture</strong></p> -->
      <h2 class="subtitle has-text-centered">
        <strong>UniFusion</strong> is the first architecture that uses only VLM as input-condition encoder without auxiliary signals from VAE or CLIP to do editing. The unified encoder framework and our proposed Layerwise Attention Pooling (LAP) module enables emergent capabilities such as <strong>zero-shot multi-reference generation</strong> when trained on single-reference pairs, and capability transfer where training on Editing helps T2I quantitatively and qualitatively.
      </h2>
    </div>
  </div>
</section>



<section class="section">
  <!-- Text-to-Image Results -->
  <div class="container">
    <h2 class="title is-3 has-text-centered">Text-to-Image Results</h2>
    <div class="collage" id="image-collage">
      <a class="collage-item wide-portrait" href="./static/images/text_to_image/portrait_unifusion_zeroshot_768x1080.png">
        <img src="./static/images/text_to_image/portrait_unifusion_zeroshot_768x1080.png" alt="portrait_unifusion_zero_shot" loading="lazy">
      </a>
      <a class="collage-item landscape" href="./static/images/text_to_image/landscape_18.png">
        <img src="./static/images/text_to_image/landscape_18.png" alt="landscape_18" loading="lazy">
      </a>
      <!-- <a class="collage-item landscape" href="./static/images/text_to_image/landscape_0.png">
        <img src="./static/images/text_to_image/landscape_0.png" alt="landscape_0" loading="lazy">
      </a> -->
      <a class="collage-item landscape" href="./static/images/text_to_image/landscape_1.png">
        <img src="./static/images/text_to_image/landscape_1.png" alt="landscape_1" loading="lazy">
      </a>
      <a class="collage-item landscape" href="./static/images/text_to_image/landscape_8.png">
        <img src="./static/images/text_to_image/landscape_8.png" alt="landscape_8" loading="lazy">
      </a>
      <a class="collage-item landscape" href="./static/images/text_to_image/landscape_11.png">
        <img src="./static/images/text_to_image/landscape_11.png" alt="landscape_11" loading="lazy">
      </a>
      <a class="collage-item landscape" href="./static/images/text_to_image/landscape_13.png">
        <img src="./static/images/text_to_image/landscape_13.png" alt="landscape_13" loading="lazy">
      </a>
      <a class="collage-item landscape" href="./static/images/text_to_image/landscape_14.png">
        <img src="./static/images/text_to_image/landscape_14.png" alt="landscape_14" loading="lazy">
      </a>
      <a class="collage-item portrait" href="./static/images/text_to_image/portrait_3_512x720.png">
        <img src="./static/images/text_to_image/portrait_3_512x720.png" alt="portrait_3" loading="lazy">
      </a>
      <!-- <a class="collage-item portrait" href="./static/images/text_to_image/portrait_1.png">
        <img src="./static/images/text_to_image/portrait_1.png" alt="portrait_1" loading="lazy">
      </a> -->
      <a class="collage-item portrait" href="./static/images/text_to_image/portrait_18.png">
        <img src="./static/images/text_to_image/portrait_18.png" alt="portrait_18" loading="lazy">
      </a>
      <!-- <a class="collage-item portrait" href="./static/images/text_to_image/portrait_7.png">
        <img src="./static/images/text_to_image/portrait_7.png" alt="portrait_7" loading="lazy">
      </a> -->
      <a class="collage-item landscape" href="./static/images/text_to_image/landscape_2.png">
        <img src="./static/images/text_to_image/landscape_2.png" alt="landscape_2" loading="lazy">
      </a>
      <a class="collage-item landscape" href="./static/images/text_to_image/landscape_20.png">
        <img src="./static/images/text_to_image/landscape_20.png" alt="landscape_20" loading="lazy">
      </a>
    </div>
  </div>
</section>


<section class="section">
  <!-- Text-to-Image Results -->
  <div class="container">
    <h2 class="title is-3 has-text-centered">Single-reference editing results</h2>
    <h2 class="subtitle is-5 has-text-centered" style="padding-top: 10px;">
      Hover to see the full edited image and instruction prompts.
    </h2>
    <div class="collage collage--editing" id="image-collage-editing">
    <!-- <div class="collage" id="image-collage"> -->
      <a class="collage-item portrait" href="./static/images/single_ref_editing/portrait_005_character_repose_cropped.png">
        <img src="./static/images/single_ref_editing/portrait_005_character_repose_cropped.png" alt="portrait_005_character_repose" loading="lazy">
        <div class="prompt-overlay">a photo of this cat swimming in a river in a jungle, go pro action footage</div>
      </a>
      <a class="collage-item portrait" href="./static/images/single_ref_editing/portrait_001_color_change.png">
        <img src="./static/images/single_ref_editing/portrait_001_color_change.png" alt="portrait_001_color_change" loading="lazy">
        <div class="prompt-overlay">change the color to the wall of the house to yellow</div>
      </a>
      <a class="collage-item landscape" href="./static/images/single_ref_editing/landscape_001_text_editing.png">
        <img src="./static/images/single_ref_editing/landscape_001_text_editing.png" alt="landscape_001_text_editing" loading="lazy">
        <div class="prompt-overlay">change the words to say "watch out above you"</div>
      </a>
      <a class="collage-item landscape" href="./static/images/single_ref_editing/landscape_002_character_repose.png">
        <img src="./static/images/single_ref_editing/landscape_002_character_repose.png" alt="landscape_002_character_repose" loading="lazy">
        <div class="prompt-overlay">Using the reference portrait as identity, generate a new image of the same woman throwing pottery at a wheel in a rustic studio. Keep facial features, hair color/part, approximate age, and skin texture consistent. Hands should be clay-smeared; add soft daylight from a high window plus a warm rim light from camera right. 35 mm, f/2.0, chest-level angle</div>
      </a>
      <a class="collage-item square" href="./static/images/single_ref_editing/square_001_expression_change.png">
        <img src="./static/images/single_ref_editing/square_001_expression_change.png" alt="square_001_expression_change" loading="lazy">
        <div class="prompt-overlay">change this character to smiling</div>
      </a>
      <a class="collage-item portrait" href="./static/images/single_ref_editing/portrait_002_character_repose.png">
        <img src="./static/images/single_ref_editing/portrait_002_character_repose.png" alt="portrait_002_character_repose" loading="lazy">
        <div class="prompt-overlay">Generate an image of this photo showing the whole body of the subject. The subject is wearing a fluffy white headband.</div>
      </a>
      <a class="collage-item landscape" href="./static/images/single_ref_editing/landscape_003_text_editing.png">
        <img src="./static/images/single_ref_editing/landscape_003_text_editing.png" alt="landscape_003_text_editing" loading="lazy">
        <div class="prompt-overlay">change the "STOP" to "START"</div>
      </a>
      <a class="collage-item portrait" href="./static/images/single_ref_editing/portrait_003_object_extraction.png">
        <img src="./static/images/single_ref_editing/portrait_003_object_extraction.png" alt="portrait_003_object_extraction" loading="lazy">
        <div class="prompt-overlay">Isolate only the rosemary on yellow background</div>
      </a>
      <a class="collage-item landscape" href="./static/images/single_ref_editing/landscape_004_stylization.png">
        <img src="./static/images/single_ref_editing/landscape_004_stylization.png" alt="landscape_004_stylization" loading="lazy">
        <div class="prompt-overlay">Using this style make some art of a boat in the harbor of an old town</div>
      </a>
      <a class="collage-item portrait" href="./static/images/single_ref_editing/portrait_004_character_repose.png">
        <img src="./static/images/single_ref_editing/portrait_004_character_repose.png" alt="portrait_004_character_repose" loading="lazy">
        <div class="prompt-overlay">Same woman in a modern lab wearing a white coat and nitrile gloves, holding a pipette near a rack; match facial structure and hair color; neutral white balance.</div>
      </a>
      <a class="collage-item landscape" href="./static/images/single_ref_editing/portrait_006_extraction_change_ar.png">
        <img src="./static/images/single_ref_editing/portrait_006_extraction_change_ar.png" alt="portrait_006_extraction_change_ar" loading="lazy">
        <div class="prompt-overlay">Place the dog on a white background</div>
      </a>
      <a class="collage-item landscape" href="./static/images/single_ref_editing/landscape_005_extraction_change_ar.png">
        <img src="./static/images/single_ref_editing/landscape_005_extraction_change_ar.png" alt="landscape_005_extraction_change_ar" loading="lazy">
        <div class="prompt-overlay">add earrings to a white marble round stand, add delicate shadows in the background of the flowers, place a white rose next to the stand</div>
      </a>
    </div>
  </div>
</section>


<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="carousel-label" class="column is-full-width">
        <div class="column has-text-centered">
          <h2 class="title is-3 has-text-centered">Zero-shot multi-reference generations</h2>
        </div>
      </div>
      <div id="carousel-div" class="carousel results-carousel" data-autoplay="true" data-pagination="true" data-navigation="true" data-delay="3000">
        <div class="item"><img src="./static/images/multi_ref_editing/three_ref_001.png" alt="carousel placeholder 1"></div>
        <div class="item"><img src="./static/images/multi_ref_editing/three_ref_002.png" alt="carousel placeholder 2"></div>
        <div class="item"><img src="./static/images/multi_ref_editing/two_ref_001.png" alt="carousel placeholder 3"></div>
        <div class="item"><img src="./static/images/multi_ref_editing/two_ref_002.png" alt="carousel placeholder 4"></div>
        <div class="item"><img src="./static/images/multi_ref_editing/two_ref_003.png" alt="carousel placeholder 5"></div>
        <div class="item"><img src="./static/images/multi_ref_editing/two_ref_004.png" alt="carousel placeholder 6"></div>
      </div>
    </div>
    <div class="container is-max-desktop">
      <p class="content has-text-justified" style="margin-top: 15px;">
        <span>When UniFusion is trained on single-reference pairs, it generalizes well when user inputs multiple reference images.</span>
        <span>Results shown are generated by a UniFusion checkpoint trained for roughly 11k steps on editing and has <em>never</em> seen multi-reference pairs.</span>
        <span><strong>Hover over the image to pause the carousel!</strong></span>
      </p>
    </div>
  </div>
</section>


<section class="section fullwidth-gray-bg">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We present UniFusion, a diffusion-based generative model conditioned on a frozen large vision-language model (VLM) that serves as a unified multimodal encoder. Although recent advances in visual generation have been remarkable, most existing architectures still depend on distinct encoders for images (e.g., Variational Autoencoder i.e. VAE features) and text (e.g., T5 or CLIP). This separation constrains diffusion models’ ability to perform cross-modal reasoning and knowledge transfer. Prior attempts to bridge this gap often perform shallow fusion of information from VLM without enough generalization, employ multiple visual encoders, or train large unified VLMs jointly for text and image generation—approaches that demand substantial computational resources and large-scale data, limiting accessibility. To reap the benefits of the joint multimodal reasoning and representation capacity of VLMs, we propose UniFusion. 
          </p>

          <!-- <p>
            Specifically, we derive a closed-form solution for a 2D Gaussian-to-hologram transform that supports 
            occlusions and alpha blending. Inspired by classic computer graphics techniques, we also derive an efficient 
            approximation of the aforementioned process in the Fourier domain that is easily parallelizable and 
            implement it using custom CUDA kernels. 
          </p> -->
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
<!-- Model Pipeline. -->
<div class="columns is-centered has-text-centered">
  <div class="column is-full-width">
    <h2 class="title is-3">Conditioning Architectures</h2>
    <div class="content has-text-centered">
      <img src="./static/images/overview_with_vqa_score.png" style="width: 100%;">
    </div>
    <div class="content has-text-justified">
      <p>
        We begin by ablating four conditioning strategies — including the conventional last-layer, key-value fusion, and hidden-state injection — and find that Layerwise Attention Pooling (LAP) consistently performs best across tasks. However, LAP alone is not a simple drop-in replacement to surpass T5, especially when the base model (e.g., Llama 3.1-8B) contains insufficient capacity. By switching to InternVL 2.5-8B in later section, which provides richer joint representations, we match and even exceed T5 performance once paired with our VeriFi rewriting mechanism, achieving both stronger prompt alignment and improved visual grounding.
      </p>
    </div>
  </div>
</div>
</section>


<section class="section">
  <div class="container is-max-desktop">
<!-- Model Pipeline. -->
<div class="columns is-centered has-text-centered">
  <div class="column is-full-width">
    <h2 class="title is-3">UniFusion Design Choices</h2>
    <div class="content has-text-centered">
      <img src="./static/images/lap_visualization_qk_cluster.png" style="width: 100%;">
    </div>
    <div class="content has-text-justified">
      <p>
        <strong>Gaussian Wave Splatting (GWS)</strong> takes a set of optimized <a href="https://surfsplatting.github.io/">2D Gaussians </a> 
        as input and outputs a hologram that can be directly displayed on emerging holographic displays. In the high level,
        each 2D Gaussian primitive is illuminated by a coherent illumination source, and the resulting illuminated and propagated wavefront 
        is recorded on a spatial light modulator (SLM) to generate the hologram. Since the parameters of the Gaussians already explicitly encode 3D informtation, 
        further splatting Gaussians using a physically-accurate wave propagation model allows for the direct reconstruction of 
        3D focal stacks with natural defocus blur when viewed on a holographic display.
      </p>
      <div class="content has-text-centered">
        <img src="./static/images/layer_dropout.png" style="width: 100%;">
      </div>
      <p>
        as input and outputs a hologram that can be directly displayed on emerging holographic displays. In the high level,
        each 2D Gaussian primitive is illuminated by a coherent illumination source, and the resulting illuminated and propagated wavefront 
        is recorded on a spatial light modulator (SLM) to generate the hologram. Since the parameters of the Gaussians already explicitly encode 3D informtation, 
        further splatting Gaussians using a physically-accurate wave propagation model allows for the direct reconstruction of 
        3D focal stacks with natural defocus blur when viewed on a holographic display.
      </p>
      <div class="content has-text-centered">
        <img src="./static/images/image_recon_metrics.png" style="width: 100%;">
      </div>
      <p>
        as input and outputs a hologram that can be directly displayed on emerging holographic displays. In the high level,
        each 2D Gaussian primitive is illuminated by a coherent illumination source, and the resulting illuminated and propagated wavefront 
        is recorded on a spatial light modulator (SLM) to generate the hologram. Since the parameters of the Gaussians already explicitly encode 3D informtation, 
        further splatting Gaussians using a physically-accurate wave propagation model allows for the direct reconstruction of 
        3D focal stacks with natural defocus blur when viewed on a holographic display.
      </p>
      <div class="content has-text-centered">
        <img src="./static/images/verifi.png" style="width: 100%;">
      </div>
      <p>
        <strong>UniFusion</strong> achieves competitive performance on DPG-Bench against much larger models trained on more data. We report average and best generation across four seeds at 1024px resolution. Macro Average is taken as mean over scores per category, whereas Micro averages scores across all prompts. Results are scored by Gemma-3-27B with extensive CoT to reduce hallucinations in scoring.
      </p>
      <div class="content has-text-centered">
        <img src="./static/images/t2i_dpg_bench.png" style="width: 80%;">
      </div>
    </div>
  </div>
</div>
</section>


<section class="section fullwidth-gray-bg">
  <div class="container is-max-desktop">
<!-- Model Pipeline. -->
<div class="columns is-centered has-text-centered">
  <div class="column is-full-width">
    <h2 class="title is-3">Capability Transfer - Editing helps text-to-image generation</h2>
    <div class="content has-text-centered">
      <img src="./static/images/capability_transfer.png" style="width: 100%;">
    </div>
    <div class="content has-text-justified">
      <p>
        <strong>Gaussian Wave Splatting (GWS)</strong> takes a set of optimized <a href="https://surfsplatting.github.io/">2D Gaussians </a> 
        as input and outputs a hologram that can be directly displayed on emerging holographic displays. In the high level,
        each 2D Gaussian primitive is illuminated by a coherent illumination source, and the resulting illuminated and propagated wavefront 
        is recorded on a spatial light modulator (SLM) to generate the hologram. Since the parameters of the Gaussians already explicitly encode 3D informtation, 
        further splatting Gaussians using a physically-accurate wave propagation model allows for the direct reconstruction of 
        3D focal stacks with natural defocus blur when viewed on a holographic display.
      </p>
    </div>
  </div>
</div>
</section>


<footer class="footer" class="fullwidth-gray-bg">
  <div class="container">
    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>
  @article{li2025unifusion,
    author={Li, Yu-Teng and Brack, Manuel and Katakol, Sudeep and Ravi, Hareesh and Kale, Ajinkya},
    title={UniFusion: A Unified Encoder for Zero-shot Multi-reference Text-to-Image Generation},
    journal={arXiv preprint arXiv:2505.06582},
    year={2025},
  }
        </code></pre>
      </div>
    </section>
    <div class="content has-text-centered">
      
      <a class="icon-link"
         href="https://arxiv.org/pdf/2505.06582">
        <i class="ai ai-arxiv"></i>
      </a>
    
      <a class="icon-link" href="" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
      <a class="icon-link" href="https://drive.google.com/file/d/1tdLECuTQ-z7GU1ueCJBeKqGuSVu9Lbry/view?usp=sharing" class="external-link" disabled>
        <i class="fab fa-google-drive"></i>
      </a>
      <br>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
